---
title: "Wine Quality Prediction Using Stacking Model And Hyperparameter Tuning"
format: html
---

## Import packages
```{python}
import warnings
warnings.filterwarnings('ignore')
# Loading the necessary packages
import random
from seaborn.palettes import color_palette
random.seed(1296)
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from pandas import read_csv
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
```

## Data
```{python}
# Load the dataset
wq_data = read_csv("dataset/winequality-red.csv",header=0)
style = [
    {'selector': 'th', 'props': [
        ('background-color', '#373c41ff'),
        ('color', 'white'),
        ('font-weight', 'bold')
    ]}
]
display(wq_data.head(5).style.set_table_styles(style).format("{:.2f}"))
display(wq_data.describe().style.set_table_styles(style).format("{:.2f}"))
```

There are 11 alcohol features in the dataset with 1 variable "quality" representing the evaluated alcohol quality that we are going to predict. The quality scores range from 3 to 8 in the dataset.

## EDA
### Pairplot
Create pairplot to observe the relationship between variables colored by "quality"
```{python}
# create pairplot
pairplot = sns.pairplot(wq_data, hue="quality", diag_kind="hist")
pairplot.fig.suptitle("Pairplot", fontsize=50, y=1.02);
```
Visually alhocols with higher levels of "Sulphates", "Alcohol", "Residual Sugar" tend to have higher quality. Next, let's graph the correlation between features and "Quality" directly.

### Correlation Heatmap
```{python}
# create correlation map
fig, ax = plt.subplots(figsize = (10,7), dpi=150)
sns.heatmap(wq_data.corr(), annot=True, linewidths=2, fmt = '.2f', cmap="crest", ax = ax)
ax.set_title("Correlation - wine features vs. wine quality scores", fontsize=18, y=1.02, x=0.5)
ax.tick_params(axis='x', rotation=45);
plt.tight_layout()
```
From the correlation heatmap, "Volatile acidity" is negatively correlated with "Quality"; "Alcohol" and "Citric acid" are positively correlated with "Quality". Next, let's plot the distribution of these three features for each alchohol quality from 3 to 8.

### Density plot
```{python}
def melt_table(df, quality):
    # filter for quality subset
    df_subset = df[df['quality'] == quality]
    df_subset_melted = df_subset.melt(
        value_vars = ['alcohol','volatile acidity','citric acid'],
        var_name = 'wine_feature',
        value_name = 'value'
    )
    df_subset_melted['quality'] = quality
    return df_subset_melted

merged_df = pd.DataFrame()
min_q = wq_data['quality'].min()
max_q = wq_data['quality'].max()
for q in range(min_q, max_q+1):
    merged_df = pd.concat([merged_df, melt_table(wq_data, q)])
```

```{python}
pairs = ((i,j) for i in [0, 1] for j in [0, 1, 2])
# Density plot
fig, axes = plt.subplots(2, 3, figsize = (20, 15), sharex=True, sharey=True, dpi=200)
for ax in axes.flat:
    ax.tick_params(axis='x', which='both', labelbottom=True)
q = 3
for idx, pair in enumerate(pairs):
    axes[pair[0], pair[1]].set_facecolor('#f2f3f4ff')
    axes[pair[0], pair[1]].set_axisbelow(True) # put the grid at the back of the layer
    axes[pair[0], pair[1]].grid(True, color = 'white', linewidth = 1)
    sns.kdeplot(ax = axes[pair[0], pair[1]], data = merged_df[merged_df['quality']==q], x = 'value', hue='wine_feature', fill=True, palette='gist_earth')
    q+=1
    axes[pair[0], pair[1]].set_xlabel(f'Alcohol Quality = {q-1}')
fig.suptitle('Wine features density distributions by wine quality scores', y=1.01, fontsize = 35)
plt.tight_layout()
```
The density plot shows that obviously the higher quality alchohol has higher "Alcohol" levels and relatively lower "Volatile acid' and "Citrid acid".

## Model
```{python}
# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier, RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import cross_val_score, RepeatedKFold, train_test_split
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE

import warnings
warnings.filterwarnings("ignore")
```

### Categorize quality scores
In order to perform classification model, it's more resonable to use categorical variable by grouping "quality" into low (3-4), medium (5-6), high (7-8) instead of using the quality score directly.
```{python}
# map quality_cat from quality
wq_data['quality_cat'] = np.where(
    wq_data['quality'].isin([3,4]), 'low',
    np.where(
        wq_data['quality'].isin([5,6]), 'medium', 'high')
)
```

### Train-test split
Before train-test split, for check the balance of the dataset by classes
```{python}
wq_data['quality_cat'].value_counts()
```

Apparently, the count of "low" and "high" are under-representing in the dataset. To balance it, we are using the resample method to oversample these 2 classes

```{python}
# resample the minority classes
smote = SMOTE()
X = wq_data[['alcohol', 'volatile acidity', 'citric acid']]
y = wq_data['quality_cat']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
```

### Baseline model
```{python}

```